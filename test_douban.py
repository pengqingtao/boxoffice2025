#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from boxoffice_scraper import BoxOfficeScraper

def test_douban_feature():
    """æµ‹è¯•è±†ç“£ç”µå½±åŠŸèƒ½"""
    print("=== æµ‹è¯•è±†ç“£ç”µå½±åŠŸèƒ½ ===")
    
    scraper = BoxOfficeScraper(debug=False)
    
    # æµ‹è¯•ä¸€äº›çŸ¥åç”µå½±
    test_movies = [
        "Lilo & Stitch",
        "Thunderbolts",
        "Avatar",
        "Titanic",
        "The Lion King"
    ]
    
    print(f"\næµ‹è¯•è±†ç“£æœç´¢åŠŸèƒ½...")
    print(f"{'è‹±æ–‡ç‰‡å':<25} {'ä¸­æ–‡ç‰‡å':<20} {'è±†ç“£è¯„åˆ†':<8}")
    print("-" * 60)
    
    for movie in test_movies:
        try:
            print(f"æ­£åœ¨æœç´¢: {movie}")
            chinese_title, douban_rating = scraper.search_douban_movie(movie)
            print(f"{movie:<25} {chinese_title:<20} {douban_rating:<8}")
            print("-" * 60)
            
        except Exception as e:
            print(f"æœç´¢ {movie} æ—¶å‡ºé”™: {e}")
            print("-" * 60)

def test_combined_features():
    """æµ‹è¯•IMDbå’Œè±†ç“£ç»„åˆåŠŸèƒ½"""
    print("\n=== æµ‹è¯•ç»„åˆåŠŸèƒ½ï¼ˆå‰2éƒ¨ç”µå½±ï¼‰===")
    
    scraper = BoxOfficeScraper(debug=False)
    
    # è·å–æœ€æ–°çš„ç¥¨æˆ¿æ•°æ®ï¼ˆåªæŠ“å‰2éƒ¨ï¼‰
    year = 2025
    month = 5
    
    try:
        month_name = scraper.get_month_name(month)
        url = scraper.base_url.format(month=month_name, year=year)
        print(f"æ­£åœ¨æŠ“å–: {url}")
        
        import requests
        response = requests.get(url, headers=scraper.headers, timeout=10)
        response.raise_for_status()
        
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(response.content, 'html.parser')
        
        table = soup.find('table', class_='a-bordered')
        if not table:
            table = soup.find('table')
        
        if not table:
            print("æœªæ‰¾åˆ°æ•°æ®è¡¨æ ¼")
            return
        
        tbody = table.find('tbody')
        if tbody:
            rows = tbody.find_all('tr')
        else:
            rows = table.find_all('tr')
            if rows and rows[0].find('th'):
                rows = rows[1:]
        
        movies_data = []
        
        # åªå¤„ç†å‰2è¡Œæ•°æ®
        for i, row in enumerate(rows[:2]):
            cells = row.find_all('td')
            if len(cells) >= 7:
                try:
                    rank = cells[0].get_text(strip=True)
                    release_cell = cells[1]
                    release_link = release_cell.find('a')
                    release_name = release_link.get_text(strip=True) if release_link else release_cell.get_text(strip=True)
                    total_gross_text = cells[7].get_text(strip=True)
                    release_date_raw = cells[8].get_text(strip=True) if len(cells) > 8 else "N/A"
                    release_date = scraper.convert_date_to_chinese(release_date_raw)
                    
                    print(f"\n--- å¤„ç†ç¬¬{i+1}éƒ¨ç”µå½±: {release_name} ---")
                    
                    # è·å–IMDbè¯„åˆ†
                    imdb_rating = scraper.search_imdb_rating(release_name)
                    
                    # è·å–è±†ç“£ä¿¡æ¯
                    chinese_title, douban_rating = scraper.search_douban_movie(release_name)
                    
                    movie_data = {
                        'æ’å': rank,
                        'è‹±æ–‡ç‰‡å': release_name,
                        'ä¸­æ–‡ç‰‡å': chinese_title,
                        'ç´¯è®¡ç¥¨æˆ¿': total_gross_text,
                        'é¦–æ˜ æ—¥æœŸ': release_date,
                        'IMDbè¯„åˆ†': imdb_rating,
                        'è±†ç“£è¯„åˆ†': douban_rating
                    }
                    
                    movies_data.append(movie_data)
                    print(f"âœ… å®Œæˆ: {rank}. {release_name} / {chinese_title}")
                    print(f"   IMDb: {imdb_rating}, è±†ç“£: {douban_rating}")
                    
                except Exception as e:
                    print(f"âŒ å¤„ç†ç¬¬{i+1}è¡Œæ•°æ®æ—¶å‡ºé”™: {e}")
                    continue
        
        # æ˜¾ç¤ºç»“æœ
        if movies_data:
            print(f"\nğŸ‰ æˆåŠŸè·å– {len(movies_data)} éƒ¨ç”µå½±çš„å®Œæ•´æ•°æ®ï¼")
            print("\nğŸ“Š æœ€ç»ˆç»“æœ:")
            print(f"{'æ’å':<4} {'è‹±æ–‡ç‰‡å':<25} {'ä¸­æ–‡ç‰‡å':<20} {'ç´¯è®¡ç¥¨æˆ¿':<15} {'é¦–æ˜ æ—¥æœŸ':<10} {'IMDb':<6} {'è±†ç“£':<6}")
            print("-" * 92)
            
            for movie in movies_data:
                rank = movie['æ’å']
                en_name = movie['è‹±æ–‡ç‰‡å'][:20] + "..." if len(movie['è‹±æ–‡ç‰‡å']) > 20 else movie['è‹±æ–‡ç‰‡å']
                cn_name = movie['ä¸­æ–‡ç‰‡å'][:15] + "..." if len(movie['ä¸­æ–‡ç‰‡å']) > 15 else movie['ä¸­æ–‡ç‰‡å']
                gross = movie['ç´¯è®¡ç¥¨æˆ¿']
                date = movie['é¦–æ˜ æ—¥æœŸ']
                imdb_rating = movie['IMDbè¯„åˆ†']
                douban_rating = movie['è±†ç“£è¯„åˆ†']
                print(f"{rank:<4} {en_name:<25} {cn_name:<20} {gross:<15} {date:<10} {imdb_rating:<6} {douban_rating:<6}")
            
            # ä¿å­˜æµ‹è¯•æ•°æ®
            filename = scraper.save_to_csv(movies_data, year, month, "data/test_douban_combined.csv")
            print(f"\nğŸ’¾ æµ‹è¯•æ•°æ®å·²ä¿å­˜åˆ°: {filename}")
        else:
            print("âŒ æœªè·å–åˆ°ä»»ä½•æ•°æ®")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # é¦–å…ˆæµ‹è¯•çº¯è±†ç“£æœç´¢åŠŸèƒ½
    test_douban_feature()
    
    # ç„¶åæµ‹è¯•ç»„åˆåŠŸèƒ½
    test_combined_features() 